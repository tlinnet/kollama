import knime.extension as knext
from kollama.base import AIPortObjectSpec
from kollama.util import main_category, ai_icon

model_category = knext.category(
    path=main_category,
    level_id="models",
    name="Models",
    description="",
    icon=ai_icon,
)

class OutputFormatOptions(knext.EnumParameterOptions):
    Text = (
        "Text",
        "Text output message generated by the model.",
    )

    JSON = (
        "JSON",
        """
        When JSON is selected, the model is constrained to only generate strings 
        that parse into valid JSON object. Make sure you include the string "JSON"
        in your prompt or system message to instruct the model to output valid JSON 
        when this mode is selected.  
        For example: "Tell me a joke. Please only reply in valid JSON."
        Please refer to the OpenAI [guide](https://platform.openai.com/docs/guides/structured-outputs/structured-outputs-vs-json-mode) 
        to see which models currently support JSON outputs.
        """,
    )


class LLMPortObjectSpec(AIPortObjectSpec):
    """Most generic spec of LLMs. Used to define the most generic LLM PortType"""

    def __init__(
        self,
        n_requests: int = 1,
    ) -> None:
        super().__init__()
        self._n_requests = n_requests

    @property
    def n_requests(self) -> int:
        return self._n_requests

    @property
    def supported_output_formats(self) -> list[OutputFormatOptions]:
        return [OutputFormatOptions.Text]


class LLMPortObject(knext.PortObject):
    def __init__(self, spec: LLMPortObjectSpec) -> None:
        super().__init__(spec)

    def serialize(self) -> bytes:
        return b""

    @classmethod
    def deserialize(cls, spec: LLMPortObjectSpec, storage: bytes):
        return cls(spec)

    def create_model(self, ctx: knext.ExecutionContext):
        raise NotImplementedError()


class ChatModelPortObjectSpec(LLMPortObjectSpec):
    """Most generic chat model spec. Used to define the most generic chat model PortType."""


class ChatModelPortObject(LLMPortObject):
    def __init__(self, spec: ChatModelPortObjectSpec) -> None:
        super().__init__(spec)

    def serialize(self):
        return b""

    @classmethod
    def deserialize(cls, spec, data: dict):
        return cls(spec)

    def create_model(self, ctx: knext.ExecutionContext):
        raise NotImplementedError()


class EmbeddingsPortObjectSpec(AIPortObjectSpec):
    """Most generic embeddings model spec. Used to define the most generic embeddings model PortType."""


class EmbeddingsPortObject(knext.PortObject):
    def __init__(self, spec: EmbeddingsPortObjectSpec) -> None:
        super().__init__(spec)

    def serialize(self):
        return b""

    @classmethod
    def deserialize(cls, spec, data: dict):
        return cls(spec)

    def create_model(self, ctx: knext.ExecutionContext):
        raise NotImplementedError()